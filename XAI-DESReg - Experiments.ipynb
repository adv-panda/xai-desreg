{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa62637b-2c49-44a6-9157-c077d6ffac6f",
   "metadata": {},
   "source": [
    "## Dynamic Ensemble Selection for Regression tasks \n",
    "\n",
    "#### Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "473e71e0-c523-44be-9f97-846a4f123a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b4360d9-5980-4449-beeb-b54cbd9d85e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "\n",
    "# static ensemble models \n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# classical models \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# metrics \n",
    "from sklearn.metrics import (mean_squared_error, \n",
    "                             mean_absolute_error, \n",
    "                             r2_score, \n",
    "                             mean_squared_log_error)\n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import datasets  \n",
    "\n",
    "# infodesreg  \n",
    "from xaidesreg import DES, DRS \n",
    "\n",
    "sns.set(style='whitegrid') \n",
    "pd.set_option('display.max_columns', None)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2755211-c4e9-4cfb-8345-bb730f1abfa0",
   "metadata": {},
   "source": [
    "#### Load dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "608f7aab-fe6a-4e59-856f-ce37d5a0d21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Datasets/Abalone/abalone-5-1tra.dat\n",
      "./Datasets/Abalone/abalone-5-1tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1286\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.944257\n",
      "./Datasets/Abalone/abalone-5-2tra.dat\n",
      "./Datasets/Abalone/abalone-5-2tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1288\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.878788\n",
      "./Datasets/Abalone/abalone-5-3tra.dat\n",
      "./Datasets/Abalone/abalone-5-3tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1290\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.970071\n",
      "./Datasets/Abalone/abalone-5-4tra.dat\n",
      "./Datasets/Abalone/abalone-5-4tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1289\n",
      "[LightGBM] [Info] Number of data points in the train set: 2672, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.963323\n",
      "./Datasets/Abalone/abalone-5-5tra.dat\n",
      "./Datasets/Abalone/abalone-5-5tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000221 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1285\n",
      "[LightGBM] [Info] Number of data points in the train set: 2672, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.966692\n",
      "Mean error DES 4.595562422323505\n",
      "Std error DES 0.27263204054022583\n",
      "Mean error DRS 4.86151896990801\n",
      "Std error DRS 0.37680809287706085\n"
     ]
    }
   ],
   "source": [
    "partition_name = './Datasets/Abalone/abalone-5-'\n",
    "# partition_name = './Datasets/Concrete/concrete-5-'\n",
    "# partition_name = './Datasets/Liver/liver-5-'\n",
    "# partition_name = './Datasets/MachineCPU/machineCPU-5-'\n",
    "# partition_name = './Datasets/Real_estate/Real_estate-5-'\n",
    "# partition_name = './Datasets/Student_marks/student_marks-5-' \n",
    "# partition_name = './Datasets/Wine_quality_red/winequality-red-5-'\n",
    "# partition_name = './Datasets/Wine_quality_white/winequality-white-5-'\n",
    "# partition_name = './Datasets/Yacht/yacht_hydrodynamics-5-'\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "errors_DES = []\n",
    "errors_DRS = []\n",
    "\n",
    "for p in range(1, n_fold+1):\n",
    "    pool_models = [\n",
    "        CatBoostRegressor(verbose=False, random_state=42),\n",
    "        # XGBRegressor(random_state=42), \n",
    "        RandomForestRegressor(random_state=42), \n",
    "        LGBMRegressor(random_state=42), \n",
    "        # Ridge(random_state=42),\n",
    "        # DecisionTreeRegressor(random_state=42),\n",
    "        LinearRegression(), \n",
    "        # KNeighborsRegressor(), \n",
    "        # SVR()\n",
    "    ]\n",
    "    # if p == 2: \n",
    "    #     continue \n",
    "        \n",
    "    name_train = partition_name+str(p)+'tra.dat'\n",
    "    print(name_train)\n",
    "    name_test = partition_name+str(p)+'tst.dat'\n",
    "    print(name_test)\n",
    "    \n",
    "    data_train = pd.read_csv(name_train, header = None)\n",
    "    X_train = data_train.iloc[:,:-1]\n",
    "    y_train = data_train.iloc[:, -1:]\n",
    "\n",
    "    cols = X_train.columns\n",
    "\n",
    "    X_train, X_dsel, y_train, y_dsel = train_test_split(X_train, y_train, test_size=0.2, random_state=42)   \n",
    "\n",
    "    data_test = pd.read_csv(name_test, header=None)\n",
    "    X_test = data_test.iloc[:,:-1]\n",
    "    y_test = data_test.iloc[:, -1:]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)  \n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_dsel  = scaler.transform(X_dsel)\n",
    "    X_test  = scaler.transform(X_test)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train, columns=cols)\n",
    "    X_dsel  = pd.DataFrame(X_dsel, columns=cols)\n",
    "    X_test  = pd.DataFrame(X_test, columns=cols)\n",
    "\n",
    "    \n",
    "    for model in pool_models: \n",
    "        model.fit(X_train, y_train) \n",
    "\n",
    "\n",
    "    der = DES(pool_regressors=pool_models, \n",
    "          k=7, \n",
    "          knn_metric='minkowski', \n",
    "          metrics='mape', \n",
    "          threshold=0.1)\n",
    "\n",
    "    der.fit(X_dsel, y_dsel)\n",
    "\n",
    "    drs = DRS(pool_regressors=pool_models, \n",
    "          k=7, \n",
    "          knn_metric='minkowski', \n",
    "          metrics='mape', \n",
    "          threshold=0.05)\n",
    "\n",
    "    drs.fit(X_dsel, y_dsel)\n",
    "\n",
    "    y_pred_DES = der.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred_DES)\n",
    "    errors_DES.append(error)\n",
    "\n",
    "    y_pred_DRS = drs.predict(X_test)\n",
    "    error = mean_squared_error(y_test, y_pred_DRS)\n",
    "    errors_DRS.append(error)\n",
    "        \n",
    "    # print('Partition: ' + str(p))\n",
    "    # print('Error DES', error) \n",
    "    \n",
    "\n",
    "mean_errors_DES = np.mean(errors_DES)\n",
    "std_errors_DES = np.std(errors_DES)\n",
    "\n",
    "print('Mean error DES', mean_errors_DES)\n",
    "print('Std error DES', std_errors_DES)\n",
    "\n",
    "\n",
    "mean_errors_DRS = np.mean(errors_DRS)\n",
    "std_errors_DRS = np.std(errors_DRS)\n",
    "\n",
    "print('Mean error DRS', mean_errors_DRS)\n",
    "print('Std error DRS', std_errors_DRS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b9d141-336e-48a7-b8df-eafa14062563",
   "metadata": {},
   "source": [
    "### Single Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b84c91-de0f-4ec3-83e2-5f789c6caef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_models = [\n",
    "        CatBoostRegressor(verbose=False, random_state=42),\n",
    "        XGBRegressor(random_state=42), \n",
    "        RandomForestRegressor(random_state=42), \n",
    "        LGBMRegressor(random_state=42), \n",
    "        Ridge(random_state=42),\n",
    "        DecisionTreeRegressor(random_state=42),\n",
    "        LinearRegression(), \n",
    "        KNeighborsRegressor(), \n",
    "        SVR()\n",
    "    ] \n",
    "\n",
    "results = {}\n",
    "for model in pool_models: \n",
    "    results[model.__class__.__name__] = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "174f64e5-1663-49ef-a051-1d17b3bf93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Datasets/Abalone/abalone-5-1tra.dat\n",
      "./Datasets/Abalone/abalone-5-1tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1286\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.944257\n",
      "./Datasets/Abalone/abalone-5-2tra.dat\n",
      "./Datasets/Abalone/abalone-5-2tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1288\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.878788\n",
      "./Datasets/Abalone/abalone-5-3tra.dat\n",
      "./Datasets/Abalone/abalone-5-3tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1290\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.970071\n",
      "./Datasets/Abalone/abalone-5-4tra.dat\n",
      "./Datasets/Abalone/abalone-5-4tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1289\n",
      "[LightGBM] [Info] Number of data points in the train set: 2672, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.963323\n",
      "./Datasets/Abalone/abalone-5-5tra.dat\n",
      "./Datasets/Abalone/abalone-5-5tst.dat\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1285\n",
      "[LightGBM] [Info] Number of data points in the train set: 2672, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 9.966692\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "for model in pool_models: \n",
    "    results[model.__class__.__name__] = [] \n",
    "\n",
    "partition_name = './Datasets/Abalone/abalone-5-'\n",
    "# partition_name = './Datasets/Concrete/concrete-5-'\n",
    "# partition_name = './Datasets/Liver/liver-5-'\n",
    "# partition_name = './Datasets/MachineCPU/machineCPU-5-'\n",
    "# partition_name = './Datasets/Real_estate/Real_estate-5-'\n",
    "# partition_name = './Datasets/Student_marks/student_marks-5-' \n",
    "# partition_name = './Datasets/Wine_quality_red/winequality-red-5-'\n",
    "# partition_name = './Datasets/Wine_quality_white/winequality-white-5-'\n",
    "# partition_name = './Datasets/Yacht/yacht_hydrodynamics-5-'\n",
    "\n",
    "n_fold = 5\n",
    "\n",
    "\n",
    "\n",
    "for p in range(1, n_fold+1):\n",
    "    pool_models = [\n",
    "        CatBoostRegressor(verbose=False, random_state=42),\n",
    "        XGBRegressor(random_state=42), \n",
    "        RandomForestRegressor(random_state=42), \n",
    "        LGBMRegressor(random_state=42), \n",
    "        Ridge(random_state=42),\n",
    "        DecisionTreeRegressor(random_state=42),\n",
    "        LinearRegression(), \n",
    "        KNeighborsRegressor(), \n",
    "        SVR()\n",
    "    ]\n",
    "    # if p == 2: \n",
    "    #     continue \n",
    "        \n",
    "    name_train = partition_name+str(p)+'tra.dat'\n",
    "    print(name_train)\n",
    "    name_test = partition_name+str(p)+'tst.dat'\n",
    "    print(name_test)\n",
    "    \n",
    "    data_train = pd.read_csv(name_train, header = None)\n",
    "    X_train = data_train.iloc[:,:-1]\n",
    "    y_train = data_train.iloc[:, -1:]\n",
    "\n",
    "    cols = X_train.columns\n",
    "\n",
    "    X_train, X_dsel, y_train, y_dsel = train_test_split(X_train, y_train, test_size=0.2, random_state=42)   \n",
    "\n",
    "    data_test = pd.read_csv(name_test, header=None)\n",
    "    X_test = data_test.iloc[:,:-1]\n",
    "    y_test = data_test.iloc[:, -1:]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)  \n",
    "    \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_dsel  = scaler.transform(X_dsel)\n",
    "\n",
    "    \n",
    "    X_test  = scaler.transform(X_test)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train, columns=cols)\n",
    "    X_dsel  = pd.DataFrame(X_dsel, columns=cols)\n",
    "    X_test  = pd.DataFrame(X_test, columns=cols)\n",
    "\n",
    "    \n",
    "    for model in pool_models: \n",
    "        model.fit(X_train, y_train) \n",
    "\n",
    "        pred = model.predict(X_test)\n",
    "        error = mean_squared_error(y_test, pred) \n",
    "\n",
    "        results[model.__class__.__name__].append(error)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25824d43-3211-4fd6-b19d-bac0dce6a528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error CatBoostRegressor 4.654801480687647\n",
      "Mean error XGBRegressor 5.35754589399621\n",
      "Mean error RandomForestRegressor 4.772632764031745\n",
      "Mean error LGBMRegressor 4.806793608191304\n",
      "Mean error Ridge 5.028431261040495\n",
      "Mean error DecisionTreeRegressor 9.201431395582041\n",
      "Mean error LinearRegression 4.944613568087659\n",
      "Mean error KNeighborsRegressor 5.168794923072515\n",
      "Mean error SVR 4.996852069744589\n"
     ]
    }
   ],
   "source": [
    "for model in list(results.keys()): \n",
    "    print(f'Mean error {model}', np.mean(results[model]))\n",
    "    # print(f'Std error {model}', np.std(results[model]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ad8180-3557-47ee-a22f-51a4c63548fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.654801480687647\n",
      "5.35754589399621\n",
      "4.772632764031745\n",
      "4.806793608191304\n",
      "5.028431261040495\n",
      "9.201431395582041\n",
      "4.944613568087659\n",
      "5.168794923072515\n",
      "4.996852069744589\n"
     ]
    }
   ],
   "source": [
    "for model in list(results.keys()): \n",
    "    print(np.mean(results[model]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2d1634-f4e5-4375-a635-a3d0a2c00398",
   "metadata": {},
   "source": [
    "##### End of file "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
